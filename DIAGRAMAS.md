# Diagramas del Proyecto HPC-MLP-Engine

## 1. Arquitectura General del Proyecto

```mermaid
graph TB
    subgraph "Dataset"
        MNIST["MNIST Dataset<br/>60K Train / 10K Test<br/>28x28 imÃ¡genes"]
    end
    
    subgraph "Secuencial"
        SEQC["C Secuencial<br/>clock()"]
        SEQPY["Python Secuencial<br/>time.time()"]
    end
    
    subgraph "Paralelo"
        OMP["OpenMP<br/>omp_get_wtime()"]
        MP["Multiprocessing<br/>time.time()"]
        CUDA["PyCUDA<br/>time.perf_counter()"]
    end
    
    subgraph "AnÃ¡lisis"
        RESULTS["Resultados<br/>Speedup<br/>Eficiencia<br/>Accuracy"]
    end
    
    MNIST --> SEQC
    MNIST --> SEQPY
    MNIST --> OMP
    MNIST --> MP
    MNIST --> CUDA
    
    SEQC --> RESULTS
    SEQPY --> RESULTS
    OMP --> RESULTS
    MP --> RESULTS
    CUDA --> RESULTS
```

---

## 2. Arquitectura de la Red Neuronal MLP

```mermaid
graph LR
    Input["Input Layer<br/>784 neuronas<br/>28x28 pixels"]
    
    Hidden["Hidden Layer<br/>500 neuronas<br/>ReLU activation"]
    
    Output["Output Layer<br/>10 neuronas<br/>Softmax"]
    
    Input -->|W1: 784x500<br/>b1: 500| Hidden
    Hidden -->|W2: 500x10<br/>b2: 10| Output
    
    style Input fill:#e1f5ff
    style Hidden fill:#fff3e0
    style Output fill:#f3e5f5
```

---

## 3. Flujo de Entrenamiento - Forward Pass

```mermaid
graph TD
    A["Input: X (batch_size Ã— 784)"]
    B["Z1 = X Â· W1 + b1<br/>(batch_size Ã— 500)"]
    C["A1 = ReLU(Z1)<br/>(batch_size Ã— 500)"]
    D["Z2 = A1 Â· W2 + b2<br/>(batch_size Ã— 10)"]
    E["A2 = Softmax(Z2)<br/>(batch_size Ã— 10)"]
    F["Predicciones<br/>argmax(A2)"]
    
    A --> B
    B --> C
    C --> D
    D --> E
    E --> F
    
    style A fill:#e1f5ff
    style F fill:#f3e5f5
```

---

## 4. Flujo de Entrenamiento - Backward Pass

```mermaid
graph TD
    A["Loss Function<br/>Cross-Entropy"]
    B["dL/dA2 = A2 - Y<br/>(batch_size Ã— 10)"]
    C["dL/dZ2 = dL/dA2<br/>(batch_size Ã— 10)"]
    D["dL/dW2 = A1áµ€ Â· dZ2<br/>(500 Ã— 10)"]
    E["dL/db2 = sum(dZ2)"]
    F["dL/dA1 = dZ2 Â· W2áµ€<br/>(batch_size Ã— 500)"]
    G["dL/dZ1 = dL/dA1 * ReLU'<br/>(batch_size Ã— 500)"]
    H["dL/dW1 = Xáµ€ Â· dZ1<br/>(784 Ã— 500)"]
    I["dL/db1 = sum(dZ1)"]
    
    A --> B
    B --> C
    C --> D
    C --> E
    D --> F
    E --> F
    F --> G
    G --> H
    G --> I
    
    style A fill:#ffe0b2
    style D fill:#c8e6c9
    style H fill:#c8e6c9
```

---

## 5. Estructura de Directorios

```mermaid
graph TB
    ROOT["HPC-MLP-Engine"]
    
    Dataset["ğŸ“ Dataset/<br/>archive/<br/>  â”œâ”€ train-images.idx3-ubyte<br/>  â”œâ”€ train-labels.idx1-ubyte<br/>  â”œâ”€ t10k-images.idx3-ubyte<br/>  â””â”€ t10k-labels.idx1-ubyte"]
    
    Secuencial["ğŸ“ Secuencial/"]
    SeqC["ğŸ“ C/<br/>  â”œâ”€ main.c<br/>  â”œâ”€ build_run.sh<br/>  â””â”€ [network, linalg, common]"]
    SeqPy["ğŸ“ Python/<br/>  â”œâ”€ Main.py<br/>  â””â”€ src/<br/>     â”œâ”€ MLP.py<br/>     â”œâ”€ DenseLayer.py<br/>     â”œâ”€ Activations.py<br/>     â””â”€ DataLoader.py"]
    
    Paralelo["ğŸ“ Paralelo/"]
    OMP["ğŸ“ OpenMP/<br/>  â”œâ”€ main.c<br/>  â”œâ”€ build_run.sh<br/>  â””â”€ [network, linalg, common]"]
    MP["ğŸ“ Multiprocessing/<br/>  â”œâ”€ Main.py<br/>  â””â”€ src/<br/>     â””â”€ [MLP, DenseLayer, ...]"]
    CUDA["ğŸ“ PyCuda/<br/>  â””â”€ train_pycuda.py"]
    
    ROOT --> Dataset
    ROOT --> Secuencial
    ROOT --> Paralelo
    
    Secuencial --> SeqC
    Secuencial --> SeqPy
    
    Paralelo --> OMP
    Paralelo --> MP
    Paralelo --> CUDA
```

---

## 6. ComparaciÃ³n de MÃ©todos de MediciÃ³n de Tiempo

```mermaid
graph LR
    A["C Secuencial<br/>clock()"]
    B["Python Secuencial<br/>time.time()"]
    C["OpenMP<br/>omp_get_wtime()"]
    D["Multiprocessing<br/>time.time()"]
    E["PyCUDA<br/>time.perf_counter()<br/>+ Event timing"]
    
    A -.->|Wall-clock| A1["âŒ Mide CPU<br/>time consumed"]
    B -.->|Wall-clock| B1["âœ… Mide tiempo real<br/>transcurrido"]
    C -.->|Wall-clock| C1["âœ… Recomendado para<br/>OpenMP"]
    D -.->|Wall-clock| D1["âœ… Mide tiempo real<br/>+ overhead<br/>multiprocessing"]
    E -.->|Wall-clock| E1["âœ… Mide tiempo GPU<br/>+ transferencias<br/>+ CPU"]
    
    style A fill:#ffcdd2
    style B fill:#c8e6c9
    style C fill:#c8e6c9
    style D fill:#c8e6c9
    style E fill:#c8e6c9
```

---

## 7. Pipeline de Procesamiento - Multiprocessing

```mermaid
graph TD
    Load["Cargar MNIST<br/>60K imÃ¡genes"]
    Init["Inicializar MLP<br/>n_workers procesos"]
    
    E1["Ã‰poca 1"]
    E2["Ã‰poca 2"]
    E10["Ã‰poca 10"]
    
    Batch["Para cada batch:<br/>X_batch, Y_batch"]
    
    Fwd["Forward Pass<br/>workers paralelos"]
    Bwd["Backward Pass<br/>workers paralelos"]
    Upd["Update Weights<br/>sincronizado"]
    
    Eval["Evaluar en Test Set"]
    Results["Calcular Metrics<br/>Speedup, Efficiency"]
    
    Load --> Init
    Init --> E1
    E1 --> E2
    E2 --> E10
    
    E1 --> Batch
    Batch --> Fwd
    Fwd --> Bwd
    Bwd --> Upd
    Upd --> Eval
    Eval --> Results
    
    style Load fill:#e1f5ff
    style Fwd fill:#fff3e0
    style Bwd fill:#ffe0b2
    style Upd fill:#c8e6c9
    style Results fill:#f3e5f5
```

---

## 8. ComparaciÃ³n de Speedup: Secuencial vs Paralelo

```mermaid
graph LR
    BASE["Secuencial<br/>T = 100s<br/>Speedup = 1.0x"]
    
    OMP_RES["OpenMP<br/>T â‰ˆ 25-35s<br/>Speedup â‰ˆ 2.8x<br/>(4 threads)"]
    
    MP_RES["Multiprocessing<br/>T â‰ˆ 50-80s<br/>Speedup â‰ˆ 1.2-2.0x<br/>(1-4 procesos)"]
    
    CUDA_RES["PyCUDA<br/>T â‰ˆ 15-20s<br/>Speedup â‰ˆ 5-7x<br/>(GPU)"]
    
    BASE -->|2.8x| OMP_RES
    BASE -->|1.5-2x| MP_RES
    BASE -->|5-7x| CUDA_RES
    
    style BASE fill:#ffcdd2
    style OMP_RES fill:#fff9c4
    style MP_RES fill:#fff9c4
    style CUDA_RES fill:#c8e6c9
```

---

## 9. Operaciones Clave y Paralelismo - OpenMP

```mermaid
graph TD
    subgraph "Forward Pass"
        FP1["X Â· W1 (batchÃ—784Ã—500)<br/>100M operaciones"]
        FP2["A1 Â· W2 (batchÃ—500Ã—10)<br/>1.3M operaciones"]
    end
    
    subgraph "Backward Pass"
        BP1["A1áµ€ Â· dZ2 (784Ã—batchÃ—10)<br/>100M operaciones"]
        BP2["CÃ¡lc. gradientes<br/>Overhead bajo"]
    end
    
    subgraph "OpenMP Decision"
        D1["Â¿Suficiente trabajo?<br/>if work â‰¥ 1M ops"]
        YES["âœ… Paralelizar<br/>#pragma omp"]
        NO["âŒ Secuencial SIMD<br/>#pragma omp simd"]
    end
    
    FP1 --> D1
    FP2 --> D1
    BP1 --> D1
    BP2 --> D1
    
    D1 --> YES
    D1 --> NO
    
    style FP1 fill:#c8e6c9
    style BP1 fill:#c8e6c9
    style YES fill:#c8e6c9
    style NO fill:#ffccbc
```

---

## 10. Flujo de EjecuciÃ³n Completo

```mermaid
sequenceDiagram
    participant User
    participant Program
    participant DataLoader
    participant Network
    participant GPU as GPU/CPU
    participant Results
    
    User->>Program: Ejecutar
    Program->>DataLoader: Cargar MNIST
    DataLoader->>DataLoader: Normalizar imÃ¡genes
    DataLoader->>Program: Retornar X_train, Y_train
    
    loop 10 Ã‰pocas
        loop Para cada batch
            Program->>Network: Forward Pass
            Network->>GPU: Operaciones matriciales
            GPU->>Network: Resultados
            Network->>Network: Backward Pass
            Network->>Network: Update Weights
        end
        Program->>Network: Evaluar en Test
    end
    
    Program->>Results: Calcular mÃ©tricas
    Results->>User: Mostrar tiempo, accuracy
```

---

## 11. Componentes Python - Arquitectura

```mermaid
graph TB
    DataLoader["DataLoader<br/>- load_mnist()<br/>- one_hot_encode()"]
    
    MLP["MLP<br/>- __init__()<br/>- forward()<br/>- backward()<br/>- train()<br/>- predict()"]
    
    DenseLayer["DenseLayer<br/>- forward()<br/>- backward()<br/>- update_weights()"]
    
    Activations["Activations<br/>- relu()<br/>- sigmoid()<br/>- softmax()"]
    
    MLP -->|usa| DenseLayer
    MLP -->|usa| Activations
    DataLoader -->|provee datos| MLP
    
    style DataLoader fill:#e1f5ff
    style MLP fill:#fff3e0
    style DenseLayer fill:#ffe0b2
    style Activations fill:#f3e5f5
```

---

## 12. Comparativa: Herramientas de MediciÃ³n de Tiempo

```mermaid
graph TB
    subgraph "C"
        C1["clock()<br/>â†’ CPU time"]
        C2["omp_get_wtime()<br/>â†’ Wall-clock time"]
    end
    
    subgraph "Python"
        P1["time.time()<br/>â†’ Wall-clock time<br/>Baja resoluciÃ³n"]
        P2["time.perf_counter()<br/>â†’ Wall-clock time<br/>Alta resoluciÃ³n"]
    end
    
    subgraph "GPU"
        G1["CUDA Events<br/>â†’ GPU execution time"]
        G2["time.perf_counter()<br/>â†’ CPU-GPU overhead"]
    end
    
    C1 -->|RecomendaciÃ³n| R1["âŒ No usar para<br/>paralelismo"]
    C2 -->|RecomendaciÃ³n| R2["âœ… Ideal para<br/>OpenMP"]
    P1 -->|RecomendaciÃ³n| R3["âœ… Suficiente para<br/>Python"]
    P2 -->|RecomendaciÃ³n| R4["âœ… Mejor para<br/>mediciones finas"]
    G1 -->|RecomendaciÃ³n| R5["âœ… Mide kernels<br/>GPU"]
    G2 -->|RecomendaciÃ³n| R6["âœ… Mide total<br/>incluyendo overhead"]
```

---

## 13. Estructura de Datos Principales

```mermaid
graph TD
    subgraph "Matrix (C)"
        M["struct Matrix<br/>- rows: int<br/>- cols: int<br/>- data: float*"]
    end
    
    subgraph "NumPy Array (Python)"
        NA["ndarray<br/>- shape: tuple<br/>- dtype: type<br/>- data: buffer"]
    end
    
    subgraph "Tensores (GPU)"
        T["CUDA Memory<br/>- device pointer<br/>- size en bytes"]
    end
    
    subgraph "Operaciones"
        OP1["MultiplicaciÃ³n de matrices"]
        OP2["Funciones de activaciÃ³n"]
        OP3["ActualizaciÃ³n de pesos"]
    end
    
    M --> OP1
    NA --> OP1
    T --> OP1
    
    M --> OP2
    NA --> OP2
    T --> OP2
    
    style M fill:#e1f5ff
    style NA fill:#fff3e0
    style T fill:#f3e5f5
```

---

## 14. Performance Scaling - Ley de Amdahl

```mermaid
graph TD
    A["FracciÃ³n Paralela: 95%<br/>FracciÃ³n Secuencial: 5%"]
    
    A --> B["Speedup(N) = 1 / (S + P/N)<br/>S = fracciÃ³n secuencial<br/>P = fracciÃ³n paralela<br/>N = nÃºmero de procesadores"]
    
    B --> C["NÃºcleos = 1: Speedup = 1.0x"]
    B --> D["NÃºcleos = 4: Speedup â‰ˆ 3.5x<br/>(limitado por 5% secuencial)"]
    B --> E["NÃºcleos = âˆ: Speedup mÃ¡x = 20x<br/>(inverso de 5%)"]
    
    style A fill:#fff3e0
    style B fill:#ffe0b2
    style C fill:#ffccbc
    style D fill:#c8e6c9
    style E fill:#c8e6c9
```

---

## 15. Benchmarking Workflow

```mermaid
flowchart TD
    A["Inicio: Preparar Sistema"]
    B["Cargar Dataset MNIST"]
    C["Ejecutar C Secuencial"]
    D["Ejecutar Python Secuencial"]
    E["Ejecutar OpenMP"]
    F["Ejecutar Multiprocessing"]
    G["Ejecutar PyCUDA"]
    H["Recolectar Tiempos"]
    I["Calcular Speedup = T_base / T_versiÃ³n"]
    J["Calcular Eficiencia = Speedup / N_procs"]
    K["Generar GrÃ¡ficas"]
    L["Guardar en CSV"]
    M["AnÃ¡lisis de Resultados"]
    N["Fin"]
    
    A --> B
    B --> C
    C --> D
    D --> E
    E --> F
    F --> G
    G --> H
    H --> I
    I --> J
    J --> K
    K --> L
    L --> M
    M --> N
    
    style B fill:#e1f5ff
    style I fill:#fff3e0
    style K fill:#c8e6c9
    style M fill:#f3e5f5
```

